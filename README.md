# Credit Card Fraud Detection

End-to-end Machine Learning project for detecting fraudulent credit card transactions using classical ML models, with a strong focus on handling highly imbalanced data.

This project is based on the well-known Kaggle Credit Card Fraud Detection dataset and was built as a learning-oriented yet production-style ML pipeline suitable for portfolio and CV usage.

---

## ğŸ“Œ Project Overview

- Binary classification problem (Fraud vs Non-Fraud)
- Extremely imbalanced dataset
- Full ML pipeline including:
  - Data preparation
  - Preprocessing & feature handling
  - Model training and validation
  - Threshold tuning
  - Model evaluation on a held-out test set
  - Model persistence and logging

---

## ğŸ“‚ Dataset

- Source: Kaggle â€“ Credit Card Fraud Detection  
  https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud

- The dataset is used **as-is**
- All preprocessing, splitting, and feature engineering are handled **inside the code**
- The `data/` directory in this repository is kept minimal; the dataset should be downloaded manually from Kaggle

---

## ğŸ§  Models Used

- Logistic Regression
- Random Forest
- Soft Voting Classifier (Ensemble)

All trained models are saved to disk and reused during testing.

---

## âš–ï¸ Handling Imbalanced Data

- Under-sampling strategy
- Stratified Train / Validation / Test split
- K-Fold strategy integrated into the training pipeline
- Custom **probability threshold tuning** instead of relying on the default 0.5 threshold

---

## ğŸ“Š Evaluation Metrics

Models are evaluated using metrics appropriate for imbalanced classification problems:

- Precision
- Recall
- F1-score
- ROC-AUC
- Confusion Matrix

### âœ… Test Set Results (Summary)

Best-performing model on the test set:

- **Model:** Random Forest  
- **Best Threshold:** 0.56  
- **F1-score:** 0.80  
- **ROC-AUC:** 0.95  

(Other models are evaluated and logged for comparison.)

---

## ğŸ§ª Data Splitting Strategy

- Stratified splitting to preserve class distribution
- Three-way split:
  - Train
  - Validation
  - Test

Approximate proportions:
- Train: 64%
- Validation: 16%
- Test: 20%

---

## ğŸ—‚ï¸ Project Structure
```bash
.
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ data.csv
â”‚   â””â”€â”€ .gitkeep
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ lr.joblib
â”‚   â”œâ”€â”€ rf.joblib
â”‚   â””â”€â”€ voting.joblib
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ EDA.ipynb
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.yaml
â”‚   â”œâ”€â”€ Data_utils.py
â”‚   â”œâ”€â”€ training.py
â”‚   â”œâ”€â”€ eval.py
â”‚   â”œâ”€â”€ helper_fun.py
â”‚   â””â”€â”€ main.py
â”œâ”€â”€ training.log
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
```





## â–¶ï¸ How to Run

All commands should be executed from the **project root directory**.

> âš ï¸ The project is designed to be executed as a Python module to ensure correct imports and configuration paths.

### Train a model
```bash
python -m src.main --model logistic_regression --mode train
```
### test a model
```bash
python -m src.main --model logistic_regression --mode test
```
### Available Models

- `logistic_regression`
- `random_forest`
- `voting`

---

## ğŸ“œ Logging

- Centralized logging using Pythonâ€™s `logging` module
- Logged information includes:
  - Model name
  - Best threshold
  - Evaluation metrics
- Logs are stored in:
```bash
training.log
```
---

## ğŸ¯ Project Goal

This is a **learning-oriented end-to-end machine learning project** designed to demonstrate:

- Proper ML pipeline design  
- Handling of real-world imbalanced datasets  
- Clean project organization  
- Reproducible training and evaluation  
- Practical use of threshold tuning and logging  

The project is intended for inclusion in a professional CV or portfolio.

---

## ğŸ“¦ Requirements

All required dependencies are listed in:

```bash
requirements.txt
```
## ğŸ‘¤ Author

**Amir**








